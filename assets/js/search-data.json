{
  
    
        "post0": {
            "title": "파노라마 이미지",
            "content": "!pwd ## 현재 디렉토리를 확인하는 코드 (리눅스 베이스) . /content/drive/My Drive/파노라마프로젝트 . %cd drive/MyDrive/파노라마프로젝트 ## 현재 디렉토리를 드라이브상의 파노라프로젝트 폴더로 이동시킨다. . [Errno 2] No such file or directory: &#39;drive/MyDrive/파노라마프로젝트&#39; /content/drive/MyDrive/파노라마프로젝트 . import numpy as np import cv2 import math import random def RANSACFilter( matched_pairs, keypoints1, keypoints2, orient_agreement, scale_agreement): &quot;&quot;&quot; This function takes in `matched_pairs`, a list of matches in indices and return a subset of the pairs using RANSAC. Inputs: matched_pairs: a list of tuples [(i, j)], indicating keypoints1[i] is matched with keypoints2[j] keypoints1, 2: keypoints from image 1 and image 2 stored in np.array with shape (num_pts, 4) each row: row, col, scale, orientation *_agreement: thresholds for defining inliers, floats Output: largest_set: the largest consensus set in [(i, j)] format HINTS: the &quot;*_agreement&quot; definitions are well-explained in the assignment instructions. &quot;&quot;&quot; assert isinstance(matched_pairs, list) assert isinstance(keypoints1, np.ndarray) assert isinstance(keypoints2, np.ndarray) assert isinstance(orient_agreement, float) assert isinstance(scale_agreement, float) ## START&#39; print(keypoints1.shape,keypoints2.shape) print(matched_pairs) repetition=10 ##반복횟수 most=0 largest_set = [] ##가장 횟수가 많은 매치쌍을 저장할 배열 matched_pairs = np.asarray(matched_pairs) ##리스트로 받은 것을 np array로 변환 for i in range(repetition): r = random.randint(0,len(matched_pairs)-1) ## 랜덤으로 matched_pairs의 인덱스 벗어나지 않는 숫자 생성 print(r) x1, y1 = matched_pairs[r][0], matched_pairs[r][1] ##R번째 좌표 획득 s1, o1 = keypoints2[y1][2]/keypoints1[x1][2], keypoints2[y1][3]/keypoints1[x1][3] ##그때의 scale factor와 orient factor 계산 tmp=0 a=[] for j in range(9): x2, y2 = matched_pairs[j][0] , matched_pairs[j][1] #다른 나머지 모두와 계산하기 위해 좌표 획득 s2, o2 = keypoints2[y2][2]/keypoints1[x2][2], keypoints2[y2][3]-keypoints1[x2][3] ##그때의 scale factor와 orient factor if abs(s2-s1) &lt;= scale_agreement * s1 and abs(o2-o1)%(2*math.pi) &lt;= orient_agreement: ##scale tolerance와 orient tolerance를 계산해 만족할시에 tmp+=1 ##횟수를 하나늘임 a.append([x2,y2]) ##그때 배열에 좌표쌍을 입력 largest_set.append(a) ## r번째 매치와 나머지를 비교했을때의 허용되는 매치들의 배열 if(tmp&gt;most): ## 만약 이갯수가 가장 많다면 most = tmp ## 최대갯수로 저장 max_i,max_len= 0 , len(largest_set[0]) ## 만족하는 매치들을 저장한 배열 for i in range(len(largest_set)): ## 배열을 탐색하면서 가장 길이가 긴것을 발견하면 그것을 최대갯수로 보고 저장 l = len(largest_set[i]) if l &gt; max_len: max_len = l max_i = i ## END assert isinstance(largest_set, list) return largest_set[i] def FindBestMatches(descriptors1, descriptors2, threshold): &quot;&quot;&quot; This function takes in descriptors of image 1 and image 2, and find matches between them. See assignment instructions for details. Inputs: descriptors: a K-by-128 array, where each row gives a descriptor for one of the K keypoints. The descriptor is a 1D array of 128 values with unit length. threshold: the threshold for the ratio test of &quot;the distance to the nearest&quot; divided by &quot;the distance to the second nearest neighbour&quot;. pseudocode-wise: dist[best_idx]/dist[second_idx] &lt;= threshold Outputs: matched_pairs: a list in the form [(i, j)] where i and j means descriptors1[i] is matched with descriptors2[j]. &quot;&quot;&quot; assert isinstance(descriptors1, np.ndarray) assert isinstance(descriptors2, np.ndarray) assert isinstance(threshold, float) ## START ## the following is just a placeholder to show you the output format num1 = descriptors1.shape[0] num2 = descriptors2.shape[0] index = [] similarity =[] for i in range(num1): fst_max_j=0 ##가장 큰값 이되는 곳의 decriptor2인덱스 sec_max_j=0 ##두번째로 큰 값 이 되는곳의 decriptor2인덱스 tmp = 0 max1 =0 ##가장 큰 값을 저장할 곳 max2 =0 ##다음 큰 값을 저장할 곳 for j in range(num2): tmp = np.dot(descriptors1[i], np.transpose(descriptors2[j])) ##두 디스크립터를 내적시킨다. tmp에 저장 if(max1 &lt;= tmp): ##만약 tmp값이 저장된 값보다 크면 max2 = max1 ## 가장 큰 값을 max2로 옮기고 max1 = tmp ## tmp를 가장 큰 값에 저장 sec_max_j = fst_max_j ## 그때의 인덱스도 저장 fst_max_j = j if( (np.arccos(max1)/(np.arccos(max2)-np.arccos(max1))) &lt; 0.9): ##threshold를 0.84일때 가장 outlier가 없지만 0.9로 설정 index.append([i,fst_max_j]) ##인덱스 쌍을 append로 저장 similarity.append(np.dot(descriptors1[i],descriptors2[j])) matched_pairs = sorted(index,key= lambda x :math.acos(np.dot(descriptors1[x[0]],descriptors2[x[1]])),reverse=True) ##람다함수로 각도가 큰순서대로 저장 ## END return matched_pairs def KeypointProjection(xy_points, h): &quot;&quot;&quot; This function projects a list of points in the source image to the reference image using a homography matrix `h`. Inputs: xy_points: numpy array, (num_points, 2) h: numpy array, (3, 3), the homography matrix Output: xy_points_out: numpy array, (num_points, 2), input points in the reference frame. &quot;&quot;&quot; assert isinstance(xy_points, np.ndarray) assert isinstance(h, np.ndarray) assert xy_points.shape[1] == 2 assert h.shape == (3, 3) # START xy_points = np.pad(xy_points,((0,0),(0,1)),&#39;constant&#39;,constant_values=1) ##패딩을 더해준다 더해준패딩은 z축이며 1로패딩한다. xy_points_out=[] ##리턴할 배열생성 for i in range(len(xy_points)): a=np.dot(h,np.transpose(xy_points[i])) ##트랜스포즈 시켜서 h와 내적시켜준다. if a[2] ==0: a[2] = a[2] + (1e-10) ##Z값으로 나누는데 0이면 zero devide이므로 만약 0이면 매우작은수를 더해준다. a[0] = a[0] / a[2] a[1] = a[1] / a[2] a[2] = a[2] / a[2] a = a[0:2] ##Z축을 제외한 축값을 넣어준다. xy_points_out.append(a.tolist()) ##출력한 배열에 append한다. xy_points_out = np.asarray(xy_points_out) ##np array로 변환. # END return xy_points_out def RANSACHomography(xy_src, xy_ref, num_iter, tol): &quot;&quot;&quot; Given matches of keyponit xy coordinates, perform RANSAC to obtain the homography matrix. At each iteration, this function randomly choose 4 matches from xy_src and xy_ref. Compute the homography matrix using the 4 matches. Project all source &quot;xy_src&quot; keypoints to the reference image. Check how many projected keyponits are within a `tol` radius to the coresponding xy_ref points (a.k.a. inliers). During the iterations, you should keep track of the iteration that yields the largest inlier set. After the iterations, you should use the biggest inlier set to compute the final homography matrix. Inputs: xy_src: a numpy array of xy coordinates, (num_matches, 2) xy_ref: a numpy array of xy coordinates, (num_matches, 2) num_iter: number of RANSAC iterations. tol: float Outputs: h: The final homography matrix. &quot;&quot;&quot; assert isinstance(xy_src, np.ndarray) assert isinstance(xy_src, np.ndarray) assert xy_src.shape == xy_ref.shape assert xy_src.shape[1] == 2 assert isinstance(num_iter, int) assert isinstance(tol, (int, float)) tol = tol*1.0 num = xy_ref.shape[0] most_h=[] cnt_inlier=[] # START for i in range(num_iter): r1=random.randint(0,num-1) r2=random.randint(0,num-1) r3=random.randint(0,num-1) r4=random.randint(0,num-1) x1, y1, x_1, y_1 = xy_src[r1][0], xy_src[r1][1], xy_ref[r1][0], xy_ref[r1][1] x2, y2, x_2, y_2 = xy_src[r2][0], xy_src[r2][1], xy_ref[r2][0], xy_ref[r2][1] x3, y3, x_3, y_3 = xy_src[r3][0], xy_src[r3][1], xy_ref[r3][0], xy_ref[r3][1] x4, y4, x_4, y_4 = xy_src[r4][0], xy_src[r4][1], xy_ref[r4][0], xy_ref[r4][1] ref_mat = np.transpose([x_1, y_1, x_2, y_2, x_3, y_3, x_4, y_4]) line1 = [x1,y1,1, 0,0,0, (-1)*x_1*x1, (-1)*x_1*y1] line2 = [0,0,0, x1,y1,1, (-1)*y_1*x1, (-1)*y_1*y1] line3 = [x2,y2,1, 0,0,0, (-1)*x_2*x2, (-1)*x_2*y2] line4 = [0,0,0, x2,y2,1, (-1)*y_2*x2, (-1)*y_2*y2] line5 = [x3,y3,1, 0,0,0, (-1)*x_3*x3, (-1)*x_3*y3] line6 = [0,0,0, x3,y3,1, (-1)*y_3*x3, (-1)*y_3*y3] line7 = [x4,y4,1, 0,0,0, (-1)*x_4*x4, (-1)*x_4*y4] line8 = [0,0,0, x4,y4,1, (-1)*y_4*x4, (-1)*y_4*y4] mat = np.array([line1,line2,line3,line4,line5,line6,line7,line8]) mat1 = np.dot(mat.T, mat) mat1 = np.linalg.pinv(mat1) b = np.array([x_1,y_1,x_2,y_2,x_3,y_3,x_4,y_4]) mat2 = np.dot(mat.T, b.T) mat3 = np.dot(mat1, mat2) mat3 = mat3.tolist() mat3.append(1) mat2 = np.array(mat3).reshape(3,3) most_h.append(mat2) cnt=0 for j in range(num): tmp_xyz = np.array([xy_src[j][0], xy_src[j][1],1]) tmp_xy_ref = np.dot(mat2.astype(&quot;float32&quot;),np.transpose(tmp_xyz).astype(&quot;float32&quot;)) if(tmp_xy_ref[2]==0): tmp_xy_ref[2]+(1e-10) tmp_xy_ref[0] = tmp_xy_ref[0]/tmp_xy_ref[2] tmp_xy_ref[1] = tmp_xy_ref[1]/tmp_xy_ref[2] distance = math.sqrt(pow(xy_ref[j][0]-tmp_xy_ref[0],2)+pow(xy_ref[j][1]-tmp_xy_ref[1],2)) if(distance&lt;tol): cnt=cnt+1 cnt_inlier.append(cnt) most_inlier=0 most_index=0 for i in range(len(cnt_inlier)): if(cnt_inlier[i]&gt;most_inlier): most_inlier = cnt_inlier[i] most_index = i h = most_h[most_index] print(h.shape) # END assert isinstance(h, np.ndarray) assert h.shape == (3, 3) return h def FindBestMatchesRANSAC( keypoints1, keypoints2, descriptors1, descriptors2, threshold, orient_agreement, scale_agreement): &quot;&quot;&quot; Note: you do not need to change this function. However, we recommend you to study this function carefully to understand how each component interacts with each other. This function find the best matches between two images using RANSAC. Inputs: keypoints1, 2: keypoints from image 1 and image 2 stored in np.array with shape (num_pts, 4) each row: row, col, scale, orientation descriptors1, 2: a K-by-128 array, where each row gives a descriptor for one of the K keypoints. The descriptor is a 1D array of 128 values with unit length. threshold: the threshold for the ratio test of &quot;the distance to the nearest&quot; divided by &quot;the distance to the second nearest neighbour&quot;. pseudocode-wise: dist[best_idx]/dist[second_idx] &lt;= threshold orient_agreement: in degrees, say 30 degrees. scale_agreement: in floating points, say 0.5 Outputs: matched_pairs_ransac: a list in the form [(i, j)] where i and j means descriptors1[i] is matched with descriptors2[j]. Detailed instructions are on the assignment website &quot;&quot;&quot; orient_agreement = float(orient_agreement) assert isinstance(keypoints1, np.ndarray) assert isinstance(keypoints2, np.ndarray) assert isinstance(descriptors1, np.ndarray) assert isinstance(descriptors2, np.ndarray) assert isinstance(threshold, float) assert isinstance(orient_agreement, float) assert isinstance(scale_agreement, float) matched_pairs = FindBestMatches( descriptors1, descriptors2, threshold) matched_pairs_ransac = RANSACFilter( matched_pairs, keypoints1, keypoints2, orient_agreement, scale_agreement) return matched_pairs_ransac . from PIL import Image fig,ax = plt.subplots(2,3,figsize=(12,8)) image_list = [&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier1.png&#39;,&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier2.png&#39;,&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier3.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier4.png&#39;,&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier5.png&#39;,&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier6.png&#39;] print(image_list) im_list = [] for q in range(0,2): for p in range(0,3): tmp_img = Image.open(image_list[q*3+p]) ax[q][p].imshow(tmp_img) plt.show() . [&#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier1.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier2.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier3.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier4.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier5.png&#39;, &#39;/content/drive/MyDrive/파노라마프로젝트/data/Rainier6.png&#39;] . import sys import numpy as np import matplotlib.pyplot as plt import os.path as op sys.path = [&#39;../lib&#39;] + sys.path import hw_utils as utils path = &#39;./data/&#39; def create_pano( image_list, ratio_thres, canvas_height, canvas_width, num_iter, tol, figsize=(20, 20)): &quot;&quot;&quot; This function creates a panorama using a list of images. Inputs: image_list: a list of str, the path to each image (without file extensions). ratio_thres: the ratio test threshold in `FindBestMatches` canvas_height, canvas_width: The dimension of the canvas num_iter: num of iterations of performing RANSAC to find the homography matrix. tol: tolerance for keypoint projection &quot;&quot;&quot; # Get the matches from `FindBestMatches` # xy_src_list: np.array, (matches, 2) in xy format # xy_ref_list: np.array, (matches, 2) in xy format # im_list: a list of images in np.array xy_src_list, xy_ref_list, im_list = utils.PrepareData( image_list, ratio_thres) # Use the matches to estimate a homography matrix to the ref image frame # for each source image. Then project each source image to the reference # frame using the homography matrix. wrap_list = utils.ProjectImages( xy_src_list, xy_ref_list, im_list, canvas_height, canvas_width, num_iter, tol) # Merge the projected images above # Note: the first element is the reference image in warp_list result = utils.MergeWarppedImages( canvas_height, canvas_width, wrap_list) # show the final panorama plt.figure(figsize=figsize) plt.imshow(result) plt.show() def main(): canvas_height = 1000 canvas_width = 1000 image_list = [&#39;Rainier1&#39;, &#39;Rainier2&#39;,&#39;Rainier3&#39;,&#39;Rainier4&#39;,&#39;Rainier5&#39;,&#39;Rainier6&#39;] num_iter = 50 tol = 10 ratio_thres = 0.9 image_list = [op.join(path, im) for im in image_list] create_pano(image_list, ratio_thres, canvas_height, canvas_width, num_iter, tol, figsize=(20, 20)) if __name__ == &#39;__main__&#39;: main() . (3, 3) (3, 3) (3, 3) (3, 3) (3, 3) .",
            "url": "https://leejeongsueng1.github.io/learnAI/computer_vision/python/jupyter/2021/11/14/_11_15_%ED%8C%8C%EB%85%B8%EB%9D%BC%EB%A7%88_%EC%9D%B4%EB%AF%B8%EC%A7%80.html",
            "relUrl": "/computer_vision/python/jupyter/2021/11/14/_11_15_%ED%8C%8C%EB%85%B8%EB%9D%BC%EB%A7%88_%EC%9D%B4%EB%AF%B8%EC%A7%80.html",
            "date": " • Nov 14, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "이미지 필터링",
            "content": "from PIL import Image import numpy as np import matplotlib.pyplot as plt . def boxfilter(a): #함수선언 assert a%2 != 0, &#39;Dimension must be odd.&#39; # assert로 받은 변수가 홀수인지 판단 짝수일시 오류메세지 출력 return np.ones((a,a))/(a*a) # 받은변수의 크기를 행과 열로 가지는 2차원배열 생성하고 합이 1이되도록 갯수로 나누어줌 . boxfilter(3) . array([[0.11111111, 0.11111111, 0.11111111], [0.11111111, 0.11111111, 0.11111111], [0.11111111, 0.11111111, 0.11111111]]) . boxfilter(4) . AssertionError Traceback (most recent call last) &lt;ipython-input-4-5870f78beb34&gt; in &lt;module&gt;() -&gt; 1 boxfilter(4) &lt;ipython-input-2-b8a6a4465db3&gt; in boxfilter(a) 1 def boxfilter(a): #함수선언 -&gt; 2 assert a%2 != 0, &#39;Dimension must be odd.&#39; # assert로 받은 변수가 홀수인지 판단 짝수일시 오류메세지 출력 3 return np.ones((a,a))/(a*a) # 받은변수의 크기를 행과 열로 가지는 2차원배열 생성하고 합이 1이되도록 갯수로 나누어줌 AssertionError: Dimension must be odd. . boxfilter(7) . array([[0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816], [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816]]) . def gauss1d(sigma): sig = sigma #원래 시그마 값을 저장 sigma *= 6 #시그마에 6을 곱해줌 sigma = round(sigma) #반올림 수행 if(sigma%2==0): sigma+=1 # 짝수일 경우 1을 더해줌 arr1 = np.arange(sigma)-((sigma-1)/2) # 만들어진 값을 중간값을 행렬 인자 각각에 빼주어서 중간값이 0이되도록함 arr2 = np.exp(-arr1**2/(2*sig**2)) # 가우시안정규화를 수행해줌 return arr2/np.sum(arr2) #normalize후 반환 . gauss1d(0.3) . array([0.00383626, 0.99232748, 0.00383626]) . gauss1d(0.5) . array([0.10650698, 0.78698604, 0.10650698]) . def gauss2d(sigma): arr1 = gauss1d(sigma) #gauss1d함수를 수행해 배열생성 return np.outer(arr1,arr1) # np.outer함수로 자기자신끼리 외적하여 2차원 배열 생성 . gauss2d(0.5) . array([[0.01134374, 0.08381951, 0.01134374], [0.08381951, 0.61934703, 0.08381951], [0.01134374, 0.08381951, 0.01134374]]) . gauss2d(1) . array([[1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03, 1.07295826e-03, 2.39409349e-04, 1.96519161e-05], [2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02, 1.30713076e-02, 2.91660295e-03, 2.39409349e-04], [1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02, 5.85815363e-02, 1.30713076e-02, 1.07295826e-03], [1.76900911e-03, 2.15509428e-02, 9.65846250e-02, 1.59241126e-01, 9.65846250e-02, 2.15509428e-02, 1.76900911e-03], [1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02, 5.85815363e-02, 1.30713076e-02, 1.07295826e-03], [2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02, 1.30713076e-02, 2.91660295e-03, 2.39409349e-04], [1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03, 1.07295826e-03, 2.39409349e-04, 1.96519161e-05]]) . def convolve2d(array,filter): a = array.astype(np.float32) #원본이미지 배열을 np.float32의 데이터타입으로 변경시켜준다. f = filter.astype(np.float32) #필터역시 np.float32의 데이터타입으로 변경시켜준후 저장한다. fx, fy = np.shape(filter) #필터의 쉐이프를 fx, fy에 저장한다. px = int((fx-1)/2) py = int((fy-1)/2) a = np.pad(a, ((px,py),(px,py)), &#39;constant&#39;, constant_values=0) #상하 좌우의 순서로 패딩을 넣어줌 ax, ay = np.shape(a) # 원본이미지배열의 shape를 ax, ay에 저장. result = [] #빈배열 생성 for i in range(ax-fx+1): # x축으로 1만큼(stride) 이동하면서 곱수행 for j in range(ay-fy+1): #y축으로 1만큼 이동하면서 곱수행 result.append((a[i:i+fy,j:j+fy]*f).sum()) # 각 곱의 값을 합하여 result배열에 append함 -&gt; 1차원 배열(append하므로) result = np.array(result).reshape(ax-fx+1,ay-fy+1) #다시 2차원배열로 되돌린다. return result # result반환 . def gaussconvolve2d(array,sigma): filter1 = gauss2d(sigma) #필터를 gauss2d배열로 설정 return convolve2d(array,filter1) # 이미지와 필터를 합성곱에 적용 . im = Image.open(&#39;/content/drive/MyDrive/img_data/garden4.png&#39;) #이미지 불러오기 im_Gray = im.convert(&#39;L&#39;) # 이미지를 grey scale로 변환한다. plt.imshow(im_Gray,cmap=&#39;gray&#39;) #원본이미지 show plt.show() . im2 = np.asarray(im_Gray) # 이미지를 np배열로 변환 print(im2.shape) # 원본이미지의 배열크기 확인 im3_array = gaussconvolve2d(im2,3) # 이미지에 필터를 적용 시그마값=3 print(im3_array.shape) # 변환된 이미지의 배열크기 확인 im3_array = im3_array.astype(&#39;uint8&#39;) # 변환시에 데이터타입을 바꾸므로 다시 uint로 변환시켜준다. im3 = Image.fromarray(im3_array) # numpy배열을 다시 이미지로 변환 im3.save(&quot;filtered_image.png&quot;) # 이미지 저장 . (1125, 1500) (1125, 1500) . plt.imshow(im3,cmap=&#39;gray&#39;) plt.show() . def rgbgaussconvolve2d(image, sigma): x,y=image.size rgb_r=[] #각 채널별 픽셀값을 저장할 배열 선언 rgb_g=[] rgb_b=[] for i in range(0,x): for j in range(0,y): rgb = image.getpixel((i,j)) # i,j 위치에서의 RGB 획득 rgb_r.append(rgb[0]) # R채널 픽셀값 획득 rgb_g.append(rgb[1]) # G채널 픽셀값 획득 rgb_b.append(rgb[2]) # B채널 픽셀값 획득 npimage_r = np.asarray(rgb_r) #RGB채널 픽셀값들을 nparray로 변환 npimage_g = np.asarray(rgb_g) npimage_b = np.asarray(rgb_b) npimage_r = np.array(npimage_r).reshape(x,y) #각 채널별로 2차원배열로 변환 npimage_g = np.array(npimage_g).reshape(x,y) npimage_b = np.array(npimage_b).reshape(x,y) gaussed_r = gaussconvolve2d(npimage_r,3) #각 채널별로 gaussconvolve2d함수에 넣어 합성곱 수행 gaussed_g = gaussconvolve2d(npimage_g,3) gaussed_b = gaussconvolve2d(npimage_b,3) npimage_re = np.array(gaussed_r).astype(&#39;uint8&#39;) #float32로 변환된 데이터 타입을 다시 int타입으로 바꾸어줌 npimage_ge = np.array(gaussed_g).astype(&#39;uint8&#39;) npimage_be = np.array(gaussed_b).astype(&#39;uint8&#39;) result=image.copy() #복사이미지 생성 for i in range(0,x): #x축 탐색 for j in range(0,y): #y축 탐색 result.putpixel((i,j), (npimage_re[i][j],npimage_ge[i][j],npimage_be[i][j])) #각 채널별 픽셀값을 튜플로 만들어 3채널 픽셀 삽입 return result . def RGBclip(image): x,y=image.size rgb_r=[] #각 채널별 픽셀값을 저장할 배열 선언 rgb_g=[] rgb_b=[] for i in range(0,x): for j in range(0,y): rgb = image.getpixel((i,j)) # i,j 위치에서의 RGB 획득 rgb_r.append(rgb[0]) # R채널 픽셀값 획득 rgb_g.append(rgb[1]) # G채널 픽셀값 획득 rgb_b.append(rgb[2]) # B채널 픽셀값 획득 npimage_r = np.asarray(rgb_r) #RGB채널 픽셀값들을 nparray로 변환 npimage_g = np.asarray(rgb_g) npimage_b = np.asarray(rgb_b) npimage_r = np.array(npimage_r).reshape(x,y) #각 채널별로 2차원배열로 변환 npimage_g = np.array(npimage_g).reshape(x,y) npimage_b = np.array(npimage_b).reshape(x,y) npimage_r = np.clip(npimage_r,0,255) # 각 채널별 픽셀값을 0~255에서 벗어나지 않도록 설정 npimage_g = np.clip(npimage_g,0,255) npimage_b = np.clip(npimage_b,0,255) result=image.copy() #복사이미지 생성 for i in range(0,x): #x축 탐색 for j in range(0,y): #y축 탐색 result.putpixel((i,j), (npimage_r[i][j],npimage_g[i][j],npimage_b[i][j])) #각 채널별 픽셀값을 튜플로 만들어 3채널 픽셀 삽입 return result . image = Image.open(&#39;/content/drive/MyDrive/img_data/Rainier1.png&#39;) result = rgbgaussconvolve2d(image,3) plt.imshow(result) plt.show() . #고주파 이미지 만들기 image = Image.open(&#39;/content/drive/MyDrive/img_data/Rainier1.png&#39;) result = rgbgaussconvolve2d(image,3) #함수를 이용해 rgb 채널분리해서 low frequency image를 저장함 npimage = np.asarray(image) #원본이미지를 np배열로 저장 nplowfrqimg = np.asarray(result) # 첫번째 이미지의 저주파 이미지 저장 nphighfrqimg = npimage - nplowfrqimg # 원본이미지 - 저주파이미지 = 고주파이미지 nphighfrqshow = nphighfrqimg + 128 # 고주파이미지는 평균이 0인것으로 생성되므로 128을 더하여 평균이동 hfqimage = Image.fromarray(nphighfrqshow) #필로우 이미지로 변환 image.show() plt.imshow(hfqimage) plt.show() . plt.imshow(nplowfrqimg) . &lt;matplotlib.image.AxesImage at 0x7f416c1cacd0&gt; . plt.imshow(nplowfrqimg + nphighfrqimg) . &lt;matplotlib.image.AxesImage at 0x7f416c39bf90&gt; . plt.imshow(RGBclip(Image.fromarray(nplowfrqimg + nphighfrqimg +nphighfrqimg))) . &lt;matplotlib.image.AxesImage at 0x7f416bc20d90&gt; .",
            "url": "https://leejeongsueng1.github.io/learnAI/computer_vision/python/jupyter/2021/11/14/_11_15_%EC%9D%B4%EB%AF%B8%EC%A7%80%ED%95%84%ED%84%B0%EB%A7%81.html",
            "relUrl": "/computer_vision/python/jupyter/2021/11/14/_11_15_%EC%9D%B4%EB%AF%B8%EC%A7%80%ED%95%84%ED%84%B0%EB%A7%81.html",
            "date": " • Nov 14, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "인공지능, 컴퓨터비전을 공부하는 곳 배운 것을 정리하고 내 것으로 만들어 나가는 공간입니다. . . 주인장 소개 . OO대학교 컴퓨터공학부 | 밖에 없네유… | .",
          "url": "https://leejeongsueng1.github.io/learnAI/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  
  

  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://leejeongsueng1.github.io/learnAI/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}